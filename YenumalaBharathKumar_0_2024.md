# Yenumala Bharath Kumar - Azure Data Engineer Resume

## Career Objective
Azure Data Engineer with 3 years of experience in designing and implementing scalable data solutions on Microsoft Azure. Expertise in building data pipelines, data warehousing, and analytics platforms for retail organizations. Dedicated to delivering robust data solutions that drive business value and enable data-driven decision making.

## Professional Summary
- 3 years of hands-on experience in Azure Data Engineering
- Proficient in Azure Data Factory, Azure Synapse Analytics, Azure Databricks, and Power BI
- Strong background in SQL, Python, and PySpark for data processing
- Experience in developing ETL/ELT pipelines for retail domain
- Knowledge of data modeling, data warehousing, and dimensional modeling techniques
- Familiar with Azure cloud services and DevOps practices

## Technical Skills
- **Cloud Platforms:** Microsoft Azure (Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Azure Data Lake Storage Gen2, Azure SQL Database, Azure Blob Storage)
- **Programming Languages:** SQL, Python, PySpark, Scala
- **ETL/ELT Tools:** Azure Data Factory, SSIS, Azure Databricks
- **Databases:** Azure SQL Database, Azure Synapse Analytics, SQL Server, PostgreSQL
- **Data Warehousing:** Star Schema, Snowflake Schema, Dimensional Modeling
- **BI Tools:** Power BI, Azure Analysis Services
- **Version Control:** Git, Azure DevOps
- **Other Tools:** Azure Key Vault, Azure Monitor, Azure Logic Apps

## Professional Experience

### Azure Data Engineer | [Company Name] | [Location] | [Date Range]

**Roles and Responsibilities:**
- Designed and developed ETL/ELT pipelines using Azure Data Factory for retail data processing
- Built and maintained data warehouse solutions using Azure Synapse Analytics
- Developed Python and PySpark scripts for data transformation and business logic
- Created Power BI dashboards and reports for business intelligence
- Optimized data pipelines and queries for performance and cost efficiency
- Implemented data security measures including encryption and access controls
- Collaborated with business stakeholders to deliver data solutions
- Provided production support and troubleshooting for data systems
- Maintained technical documentation and participated in agile ceremonies

## Projects

### Project 1: Customer Segmentation Platform (Development Project)
**Title:** Advanced Customer Segmentation and Targeting Analytics Platform

**Description:**
Developed a comprehensive customer segmentation platform that analyzes customer purchase history, demographics, and behavior patterns to create actionable customer segments. The platform enables marketing teams to design targeted campaigns, personalize customer experiences, and optimize marketing spend across different customer groups.

**Skills Used:**
- Azure Databricks, Azure Data Factory
- Python, PySpark, Machine Learning (Clustering)
- Azure Synapse Analytics
- Power BI

**Responsibilities:**
- Designed data pipeline to aggregate customer data from multiple sources
- Developed PySpark-based clustering algorithms for customer segmentation
- Implemented RFM (Recency, Frequency, Monetary) analysis and behavioral scoring models
- Created dimensional data models in Azure Synapse Analytics for segmentation analytics
- Built Power BI dashboards for segment analysis, customer profiles, and campaign performance
- Optimized data processing workflows reducing execution time by 55%
- Implemented data privacy controls for customer data handling
- Worked with marketing team to validate segments and refine segmentation criteria

---

### Project 2: Data Lake Migration to Azure Data Lake Gen2 (Migration Project)
**Title:** On-premise Hadoop Data Lake Migration to Azure Data Lake Storage Gen2

**Description:**
Led migration of large-scale retail data lake from on-premise Hadoop infrastructure to Azure Data Lake Storage Gen2. Migrated petabytes of historical data including structured, semi-structured, and unstructured data while modernizing data processing workflows and improving accessibility for analytics teams.

**Skills Used:**
- Azure Data Lake Storage Gen2, Azure Databricks
- Hadoop, Hive, Spark
- Azure Data Factory
- Azure Synapse Analytics

**Responsibilities:**
- Assessed existing Hadoop data lake structure and data volumes
- Designed target architecture in Azure Data Lake Storage Gen2 with proper folder structures
- Developed Azure Data Factory pipelines for bulk data migration
- Migrated Hive tables and metadata to Azure Databricks and Azure Synapse Analytics
- Converted MapReduce and Spark jobs to Azure Databricks notebooks
- Implemented data validation and reconciliation processes
- Reduced data processing costs by 40% through cloud optimization
- Created migration documentation and data catalog
- Coordinated migration activities with analytics and data science teams

---

### Project 3: Real-time Data Streaming Support (Support Project)
**Title:** Production Real-time Data Streaming Pipeline Support and Monitoring

**Description:**
Provided 24/7 support for real-time data streaming pipelines processing retail transaction data, customer events, and inventory updates. Implemented comprehensive monitoring, alerting, and troubleshooting procedures to ensure high availability and low latency for real-time analytics and operational systems.

**Skills Used:**
- Azure Stream Analytics, Azure Event Hubs
- Azure Databricks, Azure Data Factory
- Kusto Query Language (KQL)
- Azure Monitor

**Responsibilities:**
- Monitored real-time streaming pipelines processing millions of events daily
- Developed Azure Monitor dashboards and alerts for stream processing health
- Investigated and resolved streaming pipeline failures and latency issues
- Optimized Stream Analytics queries and windowing functions for better performance
- Reduced average event processing latency by 50%
- Implemented automated recovery mechanisms for stream processing failures
- Created operational runbooks for common issues and troubleshooting procedures
- Coordinated with business users during streaming data outages
- Maintained streaming pipeline documentation and SLAs

---

## Education
- Bachelor's Degree in Computer Science/Information Technology/Engineering | [University Name] | [Year]

## Certifications
- Microsoft Certified: Azure Data Engineer Associate (DP-203)
- Microsoft Certified: Azure Fundamentals (AZ-900)



# Rohini - Azure Data Engineer Resume

## Career Objective
Azure Data Engineer with 3 years of experience in building enterprise data solutions on Microsoft Azure platform. Specialized in developing scalable data pipelines, data warehousing, and analytics solutions for retail organizations. Dedicated to delivering high-quality data solutions that transform business operations.

## Professional Summary
- 3 years of professional experience in Azure Data Engineering
- Expertise in Azure Data Factory, Azure Synapse Analytics, Azure Databricks, and Power BI
- Proficient in SQL, Python, and PySpark for data processing and analytics
- Experience in ETL/ELT pipeline development for retail domain
- Strong understanding of data modeling, data warehousing, and dimensional modeling
- Knowledge of Azure cloud services and DevOps practices

## Technical Skills
- **Cloud Platforms:** Microsoft Azure (Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Azure Data Lake Storage Gen2, Azure SQL Database, Azure Blob Storage)
- **Programming Languages:** SQL, Python, PySpark, Scala
- **ETL/ELT Tools:** Azure Data Factory, SSIS, Azure Databricks
- **Databases:** Azure SQL Database, Azure Synapse Analytics, SQL Server, PostgreSQL
- **Data Warehousing:** Star Schema, Snowflake Schema, Dimensional Modeling
- **BI Tools:** Power BI, Azure Analysis Services
- **Version Control:** Git, Azure DevOps
- **Other Tools:** Azure Key Vault, Azure Monitor, Azure Logic Apps

## Professional Experience

### Azure Data Engineer | [Company Name] | [Location] | [Date Range]

**Roles and Responsibilities:**
- Developed and maintained ETL/ELT pipelines using Azure Data Factory for retail data processing
- Designed and implemented data warehouse solutions using Azure Synapse Analytics
- Created Python and PySpark scripts for data transformation and data quality validations
- Built Power BI dashboards and reports for business intelligence and analytics
- Optimized data pipelines and database queries for performance improvement
- Implemented data security and compliance measures
- Worked with business analysts and data scientists to deliver data solutions
- Troubleshot production issues and provided support for data pipelines
- Maintained technical documentation and conducted knowledge sharing sessions

## Projects

### Project 1: Customer Segmentation Platform (Development Project)
**Title:** Advanced Customer Segmentation and Targeting Analytics Platform

**Description:**
Developed a comprehensive customer segmentation platform that analyzes customer purchase history, demographics, and behavior patterns to create actionable customer segments. The platform enables marketing teams to design targeted campaigns, personalize customer experiences, and optimize marketing spend across different customer groups.

**Skills Used:**
- Azure Databricks, Azure Data Factory
- Python, PySpark, Machine Learning (Clustering)
- Azure Synapse Analytics
- Power BI

**Responsibilities:**
- Designed data pipeline to aggregate customer data from multiple sources
- Developed PySpark-based clustering algorithms for customer segmentation
- Implemented RFM (Recency, Frequency, Monetary) analysis and behavioral scoring models
- Created dimensional data models in Azure Synapse Analytics for segmentation analytics
- Built Power BI dashboards for segment analysis, customer profiles, and campaign performance
- Optimized data processing workflows reducing execution time by 55%
- Implemented data privacy controls for customer data handling
- Worked with marketing team to validate segments and refine segmentation criteria

---

### Project 2: Data Lake Migration to Azure Data Lake Gen2 (Migration Project)
**Title:** On-premise Hadoop Data Lake Migration to Azure Data Lake Storage Gen2

**Description:**
Led migration of large-scale retail data lake from on-premise Hadoop infrastructure to Azure Data Lake Storage Gen2. Migrated petabytes of historical data including structured, semi-structured, and unstructured data while modernizing data processing workflows and improving accessibility for analytics teams.

**Skills Used:**
- Azure Data Lake Storage Gen2, Azure Databricks
- Hadoop, Hive, Spark
- Azure Data Factory
- Azure Synapse Analytics

**Responsibilities:**
- Assessed existing Hadoop data lake structure and data volumes
- Designed target architecture in Azure Data Lake Storage Gen2 with proper folder structures
- Developed Azure Data Factory pipelines for bulk data migration
- Migrated Hive tables and metadata to Azure Databricks and Azure Synapse Analytics
- Converted MapReduce and Spark jobs to Azure Databricks notebooks
- Implemented data validation and reconciliation processes
- Reduced data processing costs by 40% through cloud optimization
- Created migration documentation and data catalog
- Coordinated migration activities with analytics and data science teams

---

### Project 3: Real-time Data Streaming Support (Support Project)
**Title:** Production Real-time Data Streaming Pipeline Support and Monitoring

**Description:**
Provided 24/7 support for real-time data streaming pipelines processing retail transaction data, customer events, and inventory updates. Implemented comprehensive monitoring, alerting, and troubleshooting procedures to ensure high availability and low latency for real-time analytics and operational systems.

**Skills Used:**
- Azure Stream Analytics, Azure Event Hubs
- Azure Databricks, Azure Data Factory
- Kusto Query Language (KQL)
- Azure Monitor

**Responsibilities:**
- Monitored real-time streaming pipelines processing millions of events daily
- Developed Azure Monitor dashboards and alerts for stream processing health
- Investigated and resolved streaming pipeline failures and latency issues
- Optimized Stream Analytics queries and windowing functions for better performance
- Reduced average event processing latency by 50%
- Implemented automated recovery mechanisms for stream processing failures
- Created operational runbooks for common issues and troubleshooting procedures
- Coordinated with business users during streaming data outages
- Maintained streaming pipeline documentation and SLAs

---

## Education
- Bachelor's Degree in Computer Science/Information Technology/Engineering | [University Name] | [Year]

## Certifications
- Microsoft Certified: Azure Data Engineer Associate (DP-203)
- Microsoft Certified: Azure Fundamentals (AZ-900)


